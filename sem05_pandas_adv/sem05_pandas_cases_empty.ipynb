{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src='images/pandaearth.jpg' align='center' width=\"1100x\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Андан на экономе\n",
    "\n",
    "## Семинар 5: Аналитика продаж в pandas\n",
    "\n",
    "В этот раз мы с вами рассмотрим реальный продуктовый кейс по анализу продаж в некотором онлайн магазине. Поотвечаем на бизнес-вопросы, которые часто волнуют аналитиков в крупных компаниях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import scipy.stats as sts\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
    "plt.rcParams['figure.figsize'] = (8, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У вас есть данные о продажах в некотором интернет-магазине техники. \n",
    "\n",
    "- **`Order ID`** – айдишник заказа;\n",
    "    - _айдишник является уникальным номером для каждого созданного заказа и определяется в момент создания заказа_\n",
    "- **`Product`** – товар, который пользователь добавил в свой заказ;\n",
    "    - _обратите внимание, что в одном заказе может быть несколько товаров_\n",
    "- **`Quantity Ordered`** – кол-во определенного товара в заказе;\n",
    "- **`Price Each`** – цена одного определенного товара в заказе (в долл.);\n",
    "- **`Order Date`** – дата создания заказа;\n",
    "- **`Purchase Address`** – адрес доставки заказа;\n",
    "- **`User ID`** – айдишник пользователя, сделавшего заказ.\n",
    "    - _при этом один заказ относится только к одному пользователю, то есть связка Order ID – User ID является уникальной_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/sales_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предварительный анализ\n",
    "\n",
    "Перед тем, как приступать к решению конкретной задачи, нужно посмотреть на ваши данные. Понять, каким образом они устроены, какие в целом признаки у вас есть, правильно ли эти данные подгрузились, есть ли у вас пропуски, какой формат имеет каждая колонка и так далее. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что там по кол-ву наблюдений?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что там с пропусками?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Видим, что в данных есть пропуски. Причем кажется, что по каждой колонке это одни и те же строки. В таком случае мы можем просто их удалить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# кол-во колонок уменьшилось ровно на 545\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что там по формату колонок?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Видим, что все колонки имеют тип данных `object` – это не очень хорошо, ведь мы явно знаем, что `Order ID`, `User ID` и `Quantity Ordered` должны иметь тип `int`, а цена – `float`. При этом в pandas есть специальный формат для даты и по-хорошему нужно им тоже воспользоваться для колонки `Order Date`. Скорей всего такое произошло из-за пропусков, либо из-за других проблем в колонках. Нужно будет найти их и после этого подкорректировать форматы колонок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пробуем перевести колонку Order ID в int, получаем ошибку и разбираемся почему...\n",
    "df['Order ID'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в колонках почему-то лежат их названия, надо бы их выкинуть\n",
    "df[~df['Order ID'].str.isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оставляем только хорошие наблюдения\n",
    "df = df[df['Order ID'].str.isdigit()]\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# теперь пробуем перевести тип колонок еще раз\n",
    "df[['Order ID', 'Quantity Ordered', 'User ID']] = df[['Order ID', 'Quantity Ordered', 'User ID']].astype('float64')\n",
    "df[['Order ID', 'Quantity Ordered', 'User ID']] = df[['Order ID', 'Quantity Ordered', 'User ID']].astype('int64')\n",
    "df['Price Each'] = df['Price Each'].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь разберемся с датой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Order Date'] = pd.to_datetime(df['Order Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим еще раз на тип колонок\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что там с распределением признаков?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кол-во заказов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Quantity Ordered'].hist(bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['Quantity Ordered'].hist(bins=30, log=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Похоже на Пуассона"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоимость заказа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# готовим данные для графика\n",
    "df['GMV'] = df['Price Each'] * df['Quantity Ordered']\n",
    "gb = df.groupby('Order ID')['GMV'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gb.hist(bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gb.hist(bins=30, log=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Есть явные выбросы в районе $\\$2000$ и выше. Не будем пока их удалять, но будем держать в голове."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью метода `.value_counts()` можно еще смотреть на распределение значений в категориальных признаках, например, можем посмотреть, какие товары чаще всего заказывали:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Product'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На первых этапах не стоит сильно упарываться в предварительный анализ, пора переходить к задачам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кейс №1: Реклама и пиар\n",
    "\n",
    "Предположим, что перед нами стоит задача привлечения новых пользователей и удержание существующих. Для этого мы собираемся, во-первых, устраивать различные промоакции в периоды падения активности, чтобы стимулировать пользователей покупать товары, а во-вторых, запускать крупные рекламные кампании, наоборот, в период высокой активности пользователей, чтобы пользователи покупали товары именно в нашем интернет-магазине. \n",
    "\n",
    "__Как определить период, когда следует запускать разного рода акции?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычно, в таких задачах _нету единственного правильного решения_. Вам нужно накидать возможные гипотезы и варианты, а затем обсудить минусы и плюсы каждого подхода. \n",
    "\n",
    "При этом нужно всегда отталкиваться от данных, которые у вас есть, и от сроков, которые вы готовы потратить на эту задачу:\n",
    "- можно построить супер новороченный предсказательный алгоритм и потратить на него полгода, а можно пару часов посидеть в пандасе и уже придумать вполне себе хорошее решение\n",
    "\n",
    "_Одно из возможных решений:_\n",
    "1. Посмотреть на динамику кол-ва заказов по дням, возможно увидим сезонность.\n",
    "2. Посмотреть распределение выручки от заказов по месяцам.\n",
    "3. Посмотреть, в какое время суток чаще всего создают заказ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Динамика кол-ва заказов по дням"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# youre code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Динамика выручки по месяцам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# youre code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По первым двум графикам можем сказать, что \n",
    "\n",
    "> - Активность ниже всего в январе, так как посленовогодние праздники + падает летом\n",
    "> - Активность выше всего в октябре, апреле и в декабре – самые сезонные месяцы для покупки техники. Черная пятница? Новогодние праздники?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Динамика кол-ва заказов от времени суток"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# youre code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По третьему графику видно, что\n",
    "\n",
    "> Активность заказов начинает расти с самого утра и достигает пика на обед, а также на ранний вечер. Это часы свободного времени пользователей. Скорее всего пользователи вечером возвращаются домой с работы и у них есть время на заказы, либо в обеденное время. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что дальше? – Да что угодно! Можно закапываться в данные сколь угодно, пока не достигнете желаемых результатов, главное соблюдать баланс и не анализировать ради анализа.\n",
    "\n",
    "Например, мы можем посмотреть, в каком городе больше всего заказов и сказать, что баннеры запускать лучше там. Сгенерируйте собственную гипотезу и проверьте ее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# youre code again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кейс №2: Доверительный интервал для среднего чека\n",
    "\n",
    "Предположим, что вы хотите понять, а сколько денег вы в среднем получаете с одного сделанного заказа. При этом вы хотите не только получить точечную оценку, посчитав среднее по выборке, но и построить для этого среднего доверительный интервал.\n",
    "\n",
    "**Попытка №1**\n",
    "\n",
    "Мы уже знаем, что доверительный интервал для среднего можно построить из ЦПТ:\n",
    "\n",
    "$$ \n",
    "\\bar x \\overset{asy}{\\sim} N \\left(\\mu, \\frac{\\hat{\\sigma}^2}{n}\\right).\n",
    "$$ \n",
    "\n",
    "$$\n",
    "\\bar x_n \\pm z_{1 - \\frac{\\alpha}{2}} \\cdot \\frac{\\hat \\sigma}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "Давайте сделаем это"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считаем, сколько заработали с каждого заказа\n",
    "# при этом еще отберем user id для каждого заказа (позже будет видно зачем) \n",
    "#        – так как связка Order ID – User ID уникальна, можно тупо использовать максимум\n",
    "byorders = df.groupby('Order ID').agg({'GMV': 'sum', 'User ID': 'max'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# строим доверительный интервал\n",
    "alpha = 0.05\n",
    "mean_hat, std_hat, n = byorders['GMV'].mean(), byorders['GMV'].std(), byorders.shape[0]\n",
    "\n",
    "\n",
    "left, right = sts.norm.interval(1 - alpha, loc=mean_hat, scale=std_hat/np.sqrt(n))\n",
    "\n",
    "delta = right - left\n",
    "print(f\"Среднее по выборке: {mean_hat:.4}\")\n",
    "print(f\"Доверительный интервал [{left:.4}, {right:.4}] ширины {delta:.4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Однако, такой доверительный интервал не совсем корректный. Дело в том, что ЦПТ требует _независимость наблюдений_, но эта предпосылка в данном случае перестает быть верной. И вот почему...\n",
    "\n",
    "**Попытка №2**\n",
    "\n",
    "Каждый заказ относится к определенному пользователю. При этом есть пользователи, которые склонны тратить больше на площадке, а есть пользователи, которые меньше. Соответственно, если к нам приходит пользователь, готовый тратить много, то средний чек каждого его заказа будет зависимым между собой. Чтобы учесть это, перед тем как строить доверительный интервал для среднего чека, мы можем усреднить этот средний чек для каждого пользователя, а затем уже считать среднее по всей выборке. \n",
    "\n",
    "При этом усреднять можно более умно, используя идею _перевзвешивания_. В данном случае мы не будем ее использовать, но про нее можно посмотреть, например, [здесь](https://www.youtube.com/watch?v=z8CqaOQgYcI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# усредняем данные для каждого пользователя\n",
    "\n",
    "# youre code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# строим доверительный интервал\n",
    "\n",
    "# youre code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кейс №3: Рекомендации товаров\n",
    "\n",
    "Теперь предположим, что мы хотим повысить средний чек заказа. Для этого, на этапе того, как пользователь добавляет товар в корзину, мы хотим предлагать ему купить еще товары, которые скорее всего его заинтересуют, учитывая тот товар, который он уже добавил в корзину.\n",
    "\n",
    "**Как нам определить, какие товары рекомендовать конкретному пользователю?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Одно из возможных решений_ – посмотреть, какие товары пользователи покупают вместе чаще всего. Их и рекомендовать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# youre code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что дальше? – Да снова что угодно! \n",
    "\n",
    "Например, если у нас были бы данные о пользователях, то мы могли бы использовать признаки пользователей в составлении рекомендаций (кол-во его заказов в целом, возраст, ...). Кстати, обычно данные разбросаны в куче таблиц, поэтому вполне возможна такая ситуация, когда информация по товарам лежит в одной таблице, а информация по пользователям в другой таблице. Тогда вам нужно будет воспользоваться еще одним очень полезным приемом – __сджойнить 2 таблицы по ключу__. В pandas это можно сделать с помощью функции `pd.merge` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Небольшая история про джойны"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто хранить информацию в одной таблице бывает довольно неудобно. Когда у вас очень крупная IT-компания, данных настолько много, что если их добавить в одну таблицу, работать с ней будет очень неэффективно по времени и памяти. Поэтому информацию кладут в кучу разных таблиц, а над ними строят специальные *отношения* - так называемые колонки, по которым можно эти таблицы объединять. \n",
    "\n",
    "Пример устройства такой структуры хранения данных:\n",
    "\n",
    "<img src=\"https://progi.pro/media/main/82/d3/34/82d334f5b4b49d424a2460e796a30cd5.png\" height=\"200\" width=\"600\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://community.qlik.com/legacyfs/online/87693_all-joins.png\" height=\"400\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'Student': ['Tom', 'Ujin', 'Ann', 'Polina','Sam'],\n",
    "                    'group': ['01', '02', '02', '01','02']})\n",
    "df2 = pd.DataFrame({'Name': ['Tom', 'Ujin', 'Ann', 'Polina', 'Kit'],\n",
    "                    'GPA': ['7.8', '6.4', '8.3', '9', '10']})\n",
    "display(df1, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner join по умолчанию \n",
    "pd.merge(df1, df2, left_on='Student', right_on='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left join - оставляем все, что в левой таблице\n",
    "pd.merge(df1, df2, left_on='Student', right_on='Name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer join\n",
    "pd.merge(df1, df2, left_on='Student', right_on='Name', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
